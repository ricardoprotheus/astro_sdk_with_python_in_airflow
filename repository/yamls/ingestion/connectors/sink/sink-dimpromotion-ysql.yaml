apiVersion: "kafka.strimzi.io/v1beta2"
kind: "KafkaConnector"
metadata:
  # connector name
  name: "sink-dimpromotion-ysql-05b34d29"
  labels:
    # kafka connect [cluster] name
    strimzi.io/cluster: edh
spec:
  class: com.yb.connect.sink.YBSinkConnector
  tasksMax: 1
  config:
    #key.converter: "io.confluent.connect.avro.AvroConverter"
    #key.converter.schema.registry.url: "http://schema-registry-cp-schema-registry:8081"
    key.converter: org.apache.kafka.connect.storage.StringConverter
    #value.converter: org.apache.kafka.connect.storage.StringConverter
    value.converter: "io.confluent.connect.avro.AvroConverter"
    value.converter.schema.registry.url: "http://schema-registry-cp-schema-registry:8081"
    connection.url: "jdbc:postgresql://yb-tservers.database.svc.cluster.local:5433/salesdw"
    connection.user: "plumber"
    connection.password: "PlumberSDE"
    connection.attempts: "2"
    dialect.name: "PostgreSqlDatabaseDialect"
    topics: "dimpromotion_spark_stream_dwfiles"
    table.name.format: "public.dimpromotion"
    auto.create: "false"
    auto.evolve: "false"
    insert.mode: "upsert"
    pk.mode: "record_key"
    pk.fields: "PromotionKey"
    batch.size: "1500"
    delete.enabled: true