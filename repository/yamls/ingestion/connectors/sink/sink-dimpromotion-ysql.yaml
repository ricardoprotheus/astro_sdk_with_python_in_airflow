apiVersion: "kafka.strimzi.io/v1beta2"
kind: "KafkaConnector"
metadata:
  # connector name
  name: "sink-dimpromotion-ysql-05b34d30"
  labels:
    # kafka connect [cluster] name
    strimzi.io/cluster: edh
spec:
  class: io.confluent.connect.jdbc.JdbcSinkConnector
  tasksMax: 1
  config:
    input.data.format: "AVRO"
    input.key.format: "AVRO"
    key.converter: "io.confluent.connect.avro.AvroConverter"
    key.converter.schema.registry.url: "http://schema-registry-cp-schema-registry:8081"
    value.converter: "io.confluent.connect.avro.AvroConverter"
    value.converter.schema.registry.url: "http://schema-registry-cp-schema-registry:8081"
    connection.host: "yb-tservers.database.svc.cluster.local"
    connection.port: "5433"
    connection.user: "plumber"
    connection.password: "PlumberSDE"
    db.name: "salesdw"
    insert.mode: "upsert"
    table.name.format: "public.dimpromotion"
    connection.attempts: "2"
    dialect.name: "PostgreSqlDatabaseDialect"
    topics: "dimpromotion_spark_stream_dwfiles"
    table.types: "TABLE"
    auto.create: "false"
    auto.evolve: "false"
    pk.mode: "record_key"
    pk.fields: "PromotionKey"
    batch.size: "1500"
    delete.enabled: true